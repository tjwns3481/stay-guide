# ===========================================
# Roomy - Ollama ì„¤ì¹˜ ë° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ (Windows PowerShell)
# ===========================================

Write-Host "=========================================="
Write-Host "Roomy - Ollama ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ (Windows)"
Write-Host "=========================================="

# Ollama ì„¤ì¹˜ í™•ì¸
function Install-Ollama {
    Write-Host ""
    Write-Host "[1/4] Ollama ì„¤ì¹˜ í™•ì¸ ì¤‘..."

    $ollamaPath = Get-Command ollama -ErrorAction SilentlyContinue

    if ($ollamaPath) {
        Write-Host "âœ… Ollamaê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        ollama --version
    } else {
        Write-Host "Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        Write-Host ""
        Write-Host "ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:"
        Write-Host "1. https://ollama.com/download ë°©ë¬¸"
        Write-Host "2. Windows ë²„ì „ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜"
        Write-Host "3. ì„¤ì¹˜ ì™„ë£Œ í›„ ì´ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ì‹œ ì‹¤í–‰"
        Write-Host ""

        $response = Read-Host "Ollama ë‹¤ìš´ë¡œë“œ í˜ì´ì§€ë¥¼ ì—´ê¹Œìš”? (y/n)"
        if ($response -eq 'y') {
            Start-Process "https://ollama.com/download"
        }
        exit 1
    }
}

# Ollama ì„œë²„ í™•ì¸
function Start-OllamaServer {
    Write-Host ""
    Write-Host "[2/4] Ollama ì„œë²„ í™•ì¸ ì¤‘..."

    try {
        $response = Invoke-WebRequest -Uri "http://localhost:11434/api/tags" -Method GET -TimeoutSec 5 -ErrorAction SilentlyContinue
        Write-Host "âœ… Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."
    } catch {
        Write-Host "Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        Write-Host "ìƒˆ í„°ë¯¸ë„ì—ì„œ 'ollama serve' ëª…ë ¹ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
        Write-Host ""
        Write-Host "ë˜ëŠ” Ollama ì•±ì„ ì‹œì‘í•´ì£¼ì„¸ìš”."

        $response = Read-Host "ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n)"
        if ($response -ne 'y') {
            exit 1
        }
    }
}

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
function Download-Models {
    Write-Host ""
    Write-Host "[3/4] AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."

    # LLM ëª¨ë¸
    Write-Host ""
    Write-Host "LLM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: qwen3:8b (í•œêµ­ì–´ ì§€ì›, ~5GB)"
    Write-Host "ì´ ì‘ì—…ì€ ì¸í„°ë„· ì†ë„ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤..."
    ollama pull qwen3:8b
    Write-Host "âœ… qwen3:8b ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!"

    # ì„ë² ë”© ëª¨ë¸
    Write-Host ""
    Write-Host "ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: nomic-embed-text (~275MB)"
    ollama pull nomic-embed-text
    Write-Host "âœ… nomic-embed-text ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!"
}

# í™˜ê²½ë³€ìˆ˜ ì•ˆë‚´
function Show-EnvSetup {
    Write-Host ""
    Write-Host "[4/4] í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì•ˆë‚´"
    Write-Host ""
    Write-Host "=========================================="
    Write-Host ".env íŒŒì¼ì— ë‹¤ìŒ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:"
    Write-Host "=========================================="
    Write-Host ""
    Write-Host "# AI Providerë¥¼ ollamaë¡œ ë³€ê²½"
    Write-Host "AI_PROVIDER=ollama"
    Write-Host ""
    Write-Host "# Ollama ì„¤ì • (ê¸°ë³¸ê°’)"
    Write-Host "OLLAMA_BASE_URL=http://localhost:11434"
    Write-Host "OLLAMA_MODEL=qwen3:8b"
    Write-Host "OLLAMA_EMBEDDING_MODEL=nomic-embed-text"
    Write-Host "OLLAMA_NUM_CTX=8192"
    Write-Host ""
    Write-Host "=========================================="
}

# ì„¤ì¹˜ í™•ì¸
function Verify-Installation {
    Write-Host ""
    Write-Host "=========================================="
    Write-Host "ì„¤ì¹˜ í™•ì¸"
    Write-Host "=========================================="

    Write-Host ""
    Write-Host "ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡:"
    ollama list

    Write-Host ""
    Write-Host "í…ŒìŠ¤íŠ¸ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”:"
    Write-Host "  ollama run qwen3:8b"
    Write-Host '  > ì•ˆë…•í•˜ì„¸ìš”'
}

# ì™„ë£Œ ë©”ì‹œì§€
function Show-Completion {
    Write-Host ""
    Write-Host "=========================================="
    Write-Host "ğŸ‰ Ollama ì„¤ì • ì™„ë£Œ!"
    Write-Host "=========================================="
    Write-Host ""
    Write-Host "ë‹¤ìŒ ë‹¨ê³„:"
    Write-Host "1. .env íŒŒì¼ì—ì„œ AI_PROVIDER=ollama ë¡œ ë³€ê²½"
    Write-Host "2. ê°œë°œ ì„œë²„ ì¬ì‹œì‘: npm run dev"
    Write-Host "3. AI ì±—ë´‡ í…ŒìŠ¤íŠ¸"
    Write-Host ""
    Write-Host "ìœ ìš©í•œ ëª…ë ¹ì–´:"
    Write-Host "  ollama list          - ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡"
    Write-Host "  ollama run qwen3:8b  - ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸"
    Write-Host "  ollama serve         - ì„œë²„ ì‹œì‘"
    Write-Host ""
}

# ë©”ì¸ ì‹¤í–‰
Install-Ollama
Start-OllamaServer
Download-Models
Show-EnvSetup
Verify-Installation
Show-Completion
